{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb43d42-dfac-43dd-83d9-559b11ab8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "check_options = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "}\n",
    "\n",
    "# Multi-selection widget for check options\n",
    "check_selection = widgets.SelectMultiple(\n",
    "    options=check_options.keys(),\n",
    "    description='Checks:',\n",
    "    style={'description_width': 'initial'},\n",
    ")\n",
    "\n",
    "# Dictionary to store parameter widgets\n",
    "param_widgets = {}\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change):\n",
    "    selected_checks = check_selection.value\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    \n",
    "    new_widgets = []\n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            new_widgets.append(widgets.Label(value=f\"Parameters for {check}\"))\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'}\n",
    "                )\n",
    "                param_widgets[(check, param)] = param_widget\n",
    "                new_widgets.append(param_widget)\n",
    "    \n",
    "    param_box.children = new_widgets\n",
    "\n",
    "check_selection.observe(update_param_fields, names='value')\n",
    "param_box = widgets.VBox([])\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = list(check_selection.value)\n",
    "        final_dict = {}\n",
    "        \n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params:\n",
    "                params = {param: param_widgets.get((check, param)).value for param in checks_with_params[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "display(check_selection, param_box, submit_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3e69d-0c7e-4639-8cc9-622dcadb9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "check_options = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "}\n",
    "\n",
    "# Multi-selection widget for check options\n",
    "check_selection = widgets.SelectMultiple(\n",
    "    options=check_options.keys(),\n",
    "    description='Select Checks:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Dictionary to store parameter widgets\n",
    "param_widgets = {}\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change):\n",
    "    selected_checks = check_selection.value\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    \n",
    "    new_widgets = []\n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            param_widgets[check] = {}\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_widgets[check][param] = param_widget\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append(acc)\n",
    "    \n",
    "    param_box.children = new_widgets\n",
    "\n",
    "check_selection.observe(update_param_fields, names='value')\n",
    "param_box = widgets.VBox([])\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = list(check_selection.value)\n",
    "        final_dict = {}\n",
    "        \n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params:\n",
    "                params = {param: param_widgets[check][param].value for param in checks_with_params[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary')\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Tests and Configure Parameters\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    check_selection,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a034f7c-b174-4b4c-bb75-b03e8a30b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "check_options = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for a more user-friendly experience\n",
    "check_widgets = {check: widgets.Checkbox(value=False, description=check) for check in check_options.keys()}\n",
    "check_box = widgets.VBox(list(check_widgets.values()))\n",
    "\n",
    "# Dictionary to store parameter widgets\n",
    "param_widgets = {}\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [check for check, widget in check_widgets.items() if widget.value]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    \n",
    "    new_widgets = []\n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            param_widgets[check] = {}\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_widgets[check][param] = param_widget\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append(acc)\n",
    "    \n",
    "    param_box.children = new_widgets\n",
    "\n",
    "for widget in check_widgets.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [check for check, widget in check_widgets.items() if widget.value]\n",
    "        final_dict = {}\n",
    "        \n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params:\n",
    "                params = {param: param_widgets[check][param].value for param in checks_with_params[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary')\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Tests and Configure Parameters\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    check_box,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbb4a3-a936-4645-a263-ea46ec02cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea8649-07ef-4d97-8e1f-758ca7616210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "check_options = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "    # Data Integrity Checks\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    # Data Integrity Checks with Parameters\n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for a more user-friendly experience\n",
    "check_widgets = {check: widgets.Checkbox(value=False, description=check) for check in check_options.keys()}\n",
    "check_box = widgets.VBox(list(check_widgets.values()), layout=widgets.Layout(height='300px', overflow_y='auto'))\n",
    "\n",
    "# Dictionary to store parameter widgets\n",
    "param_widgets = {}\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [check for check, widget in check_widgets.items() if widget.value]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    \n",
    "    new_widgets = []\n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            param_widgets[check] = {}\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_widgets[check][param] = param_widget\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append(acc)\n",
    "    \n",
    "    param_box.children = new_widgets\n",
    "\n",
    "for widget in check_widgets.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [check for check, widget in check_widgets.items() if widget.value]\n",
    "        final_dict = {}\n",
    "        \n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params:\n",
    "                params = {param: param_widgets[check][param].value for param in checks_with_params[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Tests and Configure Parameters\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    check_box,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7f551-a6a8-4e2c-a43c-33fedc259a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d374d-b73c-47ec-8d28-17a5fd3f619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3674cd-91d8-4bac-8849-da2d145721b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define test suites\n",
    "suite_options = [\"Train-Test Checks\", \"Data Integrity Checks\"]\n",
    "suite_selector = widgets.Dropdown(\n",
    "    options=suite_options,\n",
    "    description='Suite:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "train_test_box = widgets.VBox(list(train_test_widgets.values()), layout=widgets.Layout(height='250px', overflow_y='auto'))\n",
    "data_integrity_box = widgets.VBox(list(data_integrity_widgets.values()), layout=widgets.Layout(height='250px', overflow_y='auto'))\n",
    "\n",
    "# Dictionary to store parameter widgets\n",
    "param_widgets = {}\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update checkboxes based on selected suite\n",
    "def update_suite_selection(change):\n",
    "    if suite_selector.value == \"Train-Test Checks\":\n",
    "        check_section.children = [train_test_box]\n",
    "    else:\n",
    "        check_section.children = [data_integrity_box]\n",
    "\n",
    "suite_selector.observe(update_suite_selection, names='value')\n",
    "check_section = widgets.VBox([])\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = []\n",
    "    if suite_selector.value == \"Train-Test Checks\":\n",
    "        selected_checks = [check for check, widget in train_test_widgets.items() if widget.value]\n",
    "    else:\n",
    "        selected_checks = [check for check, widget in data_integrity_widgets.items() if widget.value]\n",
    "    \n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            param_widgets[check] = {}\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_widgets[check][param] = param_widget\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append(acc)\n",
    "    \n",
    "    param_box.children = new_widgets\n",
    "\n",
    "for widget in train_test_widgets.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "for widget in data_integrity_widgets.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = []\n",
    "        if suite_selector.value == \"Train-Test Checks\":\n",
    "            selected_checks = [check for check, widget in train_test_widgets.items() if widget.value]\n",
    "        else:\n",
    "            selected_checks = [check for check, widget in data_integrity_widgets.items() if widget.value]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params:\n",
    "                params = {param: param_widgets[check][param].value for param in checks_with_params[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Suite and Tests\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    suite_selector,\n",
    "    check_section,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525302e5-293e-44a8-9ac2-e65eac3e4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define test suites\n",
    "suite_train_test = widgets.Checkbox(value=False, description=\"Train-Test Checks\")\n",
    "suite_data_integrity = widgets.Checkbox(value=False, description=\"Data Integrity Checks\")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "train_test_box = widgets.VBox([])\n",
    "data_integrity_box = widgets.VBox([])\n",
    "param_box = widgets.VBox([])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update displayed checkboxes based on suite selection\n",
    "def update_checkboxes(change=None):\n",
    "    check_sections = []\n",
    "    if suite_train_test.value:\n",
    "        check_sections.append(widgets.VBox(list(train_test_widgets.values()), layout=widgets.Layout(height='250px', overflow_y='auto')))\n",
    "    if suite_data_integrity.value:\n",
    "        check_sections.append(widgets.VBox(list(data_integrity_widgets.values()), layout=widgets.Layout(height='250px', overflow_y='auto')))\n",
    "    check_section.children = check_sections\n",
    "    update_param_fields()\n",
    "\n",
    "suite_train_test.observe(update_checkboxes, names='value')\n",
    "suite_data_integrity.observe(update_checkboxes, names='value')\n",
    "\n",
    "check_section = widgets.VBox([])\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [\n",
    "        check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "    ]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append((check, acc, param_inputs))\n",
    "    \n",
    "    param_box.children = [entry[1] for entry in new_widgets]\n",
    "    param_box.check_param_inputs = {entry[0]: entry[2] for entry in new_widgets}  # Store param inputs\n",
    "\n",
    "for widget in {**train_test_widgets, **data_integrity_widgets}.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [\n",
    "            check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "        ]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params and check in param_box.check_param_inputs:\n",
    "                params = {param_widget.description: param_widget.value for param_widget in param_box.check_param_inputs[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Suites\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    widgets.HBox([suite_train_test, suite_data_integrity]),\n",
    "    check_section,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bcf71-4143-42c6-800a-9278860d6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define test suites\n",
    "suite_train_test = widgets.Checkbox(value=False, description=\"Train-Test Checks\")\n",
    "suite_data_integrity = widgets.Checkbox(value=False, description=\"Data Integrity Checks\")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update parameter input fields dynamically\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [\n",
    "        check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "    ]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append((check, acc, param_inputs))\n",
    "    \n",
    "    param_box.children = [entry[1] for entry in new_widgets]\n",
    "    param_box.check_param_inputs = {entry[0]: entry[2] for entry in new_widgets}  # Store param inputs\n",
    "\n",
    "for widget in {**train_test_widgets, **data_integrity_widgets}.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [\n",
    "            check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "        ]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params and check in param_box.check_param_inputs:\n",
    "                params = {param_widget.description: param_widget.value for param_widget in param_box.check_param_inputs[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Layout adjustments\n",
    "check_columns = widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Data Integrity Checks\"), widgets.VBox(list(data_integrity_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "    widgets.VBox([widgets.Label(\"Train-Test Checks\"), widgets.VBox(list(train_test_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "])\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Suites\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    widgets.HBox([suite_train_test, suite_data_integrity]),\n",
    "    check_columns,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d142b-81d9-4149-99e6-7c12d817109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define test suites\n",
    "suite_train_test = widgets.Checkbox(value=False, description=\"Train-Test Checks\")\n",
    "suite_data_integrity = widgets.Checkbox(value=False, description=\"Data Integrity Checks\")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update check visibility based on suite selection\n",
    "def update_check_visibility(change=None):\n",
    "    for widget in train_test_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_train_test.value else 'none'\n",
    "    for widget in data_integrity_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_data_integrity.value else 'none'\n",
    "    update_param_fields()\n",
    "\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [\n",
    "        check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "    ]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append((check, acc, param_inputs))\n",
    "    \n",
    "    param_box.children = [entry[1] for entry in new_widgets]\n",
    "    param_box.check_param_inputs = {entry[0]: entry[2] for entry in new_widgets}  # Store param inputs\n",
    "\n",
    "for widget in {**train_test_widgets, **data_integrity_widgets}.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "suite_train_test.observe(update_check_visibility, names='value')\n",
    "suite_data_integrity.observe(update_check_visibility, names='value')\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [\n",
    "            check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "        ]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params and check in param_box.check_param_inputs:\n",
    "                params = {param_widget.description: param_widget.value for param_widget in param_box.check_param_inputs[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Layout adjustments\n",
    "check_columns = widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Data Integrity Checks\"), widgets.VBox(list(data_integrity_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "    widgets.VBox([widgets.Label(\"Train-Test Checks\"), widgets.VBox(list(train_test_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "])\n",
    "\n",
    "# Hide check options initially\n",
    "update_check_visibility()\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Suites\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    widgets.HBox([suite_train_test, suite_data_integrity]),\n",
    "    check_columns,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b8ffd6-0024-4533-9fc1-eed7ae3a814d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a84cc-b9f8-4fe4-9925-99a16b1aa0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d7f3f0-669c-49b9-88d6-1b5a2ae210c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c3e9cbde574fb49375fc9edb4d8199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select Suites', layout=Layout(margin='10px 0')), HBox(children=(Checkbox(value=Falâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define test suites\n",
    "suite_train_test = widgets.Checkbox(value=False, description=\"Train-Test Checks\")\n",
    "suite_data_integrity = widgets.Checkbox(value=False, description=\"Data Integrity Checks\")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out of Bounds\": {\"min_length\": 1, \"max_length\": 255},\n",
    "    \"Data Duplicates\": {\"max_duplicate_fraction\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update check visibility based on suite selection\n",
    "def update_check_visibility(change=None):\n",
    "    for widget in train_test_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_train_test.value else 'none'\n",
    "    for widget in data_integrity_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_data_integrity.value else 'none'\n",
    "    update_param_fields()\n",
    "\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [\n",
    "        check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "    ]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append((check, acc, param_inputs))\n",
    "    \n",
    "    param_box.children = [entry[1] for entry in new_widgets]\n",
    "    param_box.check_param_inputs = {entry[0]: entry[2] for entry in new_widgets}  # Store param inputs\n",
    "\n",
    "for widget in {**train_test_widgets, **data_integrity_widgets}.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "suite_train_test.observe(update_check_visibility, names='value')\n",
    "suite_data_integrity.observe(update_check_visibility, names='value')\n",
    "\n",
    "# Function to print final selection\n",
    "def display_selection(button):\n",
    "    import data_integrity\n",
    "    \n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [\n",
    "            check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "        ]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params and check in param_box.check_param_inputs:\n",
    "                params = {param_widget.description: param_widget.value for param_widget in param_box.check_param_inputs[check]}\n",
    "                final_dict[check] = {\"parameters\": params}\n",
    "            else:\n",
    "                final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "    \n",
    "  \n",
    "        \n",
    "\n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Layout adjustments\n",
    "check_columns = widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Data Integrity Checks\"), widgets.VBox(list(data_integrity_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "    widgets.VBox([widgets.Label(\"Train-Test Checks\"), widgets.VBox(list(train_test_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "    \n",
    "])\n",
    "\n",
    "# Hide check options initially\n",
    "update_check_visibility()\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Select Suites\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    widgets.HBox([suite_data_integrity, suite_train_test]),\n",
    "    check_columns,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e49c407-b18b-47f5-9b78-ef7cb8c1fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643dd26a-e094-4ebd-98cb-d09c743f802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53809cb8b9454901b5d56e3b954e0be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Upload Training Dataset (CSV)'), FileUpload(value=(), accept='.csv', description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Global variables to store uploaded datasets\n",
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "# Define test suites\n",
    "suite_train_test = widgets.Checkbox(value=False, description=\"Train-Test Checks\")\n",
    "suite_data_integrity = widgets.Checkbox(value=False, description=\"Data Integrity Checks\")\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "train_test_checks = {\n",
    "    \"String Mismatch Comparison\": \"StringMismatchComparison()\",\n",
    "    \"Train Test Samples Mix\": \"TrainTestSamplesMix()\",\n",
    "    \"New Label Train Test\": \"NewLabelTrainTest()\",\n",
    "    \"New Category Train Test\": \"NewCategoryTrainTest()\",\n",
    "    \"Label Drift\": \"LabelDrift()\", \n",
    "    \"Feature Drift\": \"FeatureDrift()\",\n",
    "}\n",
    "\n",
    "data_integrity_checks = {\n",
    "    \"Is Single Value\": \"IsSingleValue()\",\n",
    "    \"Special Characters\": \"SpecialCharacters()\",\n",
    "    \"Mixed Nulls\": \"MixedNulls()\",\n",
    "    \"Mixed Data Types\": \"MixedDataTypes()\",\n",
    "    \"String Length Out Of Bounds\": \"StringLengthOutOfBounds()\",\n",
    "    \"Data Duplicates\": \"DataDuplicates()\",\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\n",
    "        \"max_allowed_categorical_score\": 0.2, \n",
    "        \"max_allowed_numeric_score\": 0.2, \n",
    "        \"allowed_num_features_exceeding_threshold\": 0\n",
    "    },    \n",
    "    \"String Length Out Of Bounds\": {\"max_outliers\": 0},\n",
    "    \"Data Duplicates\": {\"max_ratio\": 0.1},\n",
    "}\n",
    "\n",
    "# Multi-selection using checkboxes for better user experience\n",
    "train_test_widgets = {check: widgets.Checkbox(value=False, description=check) for check in train_test_checks.keys()}\n",
    "data_integrity_widgets = {check: widgets.Checkbox(value=False, description=check) for check in data_integrity_checks.keys()}\n",
    "\n",
    "param_box = widgets.VBox([])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update check visibility based on suite selection\n",
    "def update_check_visibility(change=None):\n",
    "    for widget in train_test_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_train_test.value else 'none'\n",
    "    for widget in data_integrity_widgets.values():\n",
    "        widget.layout.display = 'block' if suite_data_integrity.value else 'none'\n",
    "    update_param_fields()\n",
    "\n",
    "def update_param_fields(change=None):\n",
    "    selected_checks = [\n",
    "        check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "    ]\n",
    "    param_box.children = []  # Clear previous widgets\n",
    "    new_widgets = []\n",
    "    \n",
    "    for check in selected_checks:\n",
    "        if check in checks_with_params:\n",
    "            param_inputs = []\n",
    "            for param, default_value in checks_with_params[check].items():\n",
    "                param_widget = widgets.FloatText(\n",
    "                    value=default_value, description=param, style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='90%')\n",
    "                )\n",
    "                param_inputs.append(param_widget)\n",
    "            acc = widgets.Accordion(children=[widgets.VBox(param_inputs)])\n",
    "            acc.set_title(0, f\"Parameters for {check}\")\n",
    "            new_widgets.append((check, acc, param_inputs))\n",
    "    \n",
    "    param_box.children = [entry[1] for entry in new_widgets]\n",
    "    param_box.check_param_inputs = {entry[0]: entry[2] for entry in new_widgets}  # Store param inputs\n",
    "\n",
    "for widget in {**train_test_widgets, **data_integrity_widgets}.values():\n",
    "    widget.observe(update_param_fields, names='value')\n",
    "\n",
    "suite_train_test.observe(update_check_visibility, names='value')\n",
    "suite_data_integrity.observe(update_check_visibility, names='value')\n",
    "\n",
    "# File upload handlers\n",
    "def handle_train_upload(change):\n",
    "    global train_df\n",
    "    with output:\n",
    "        clear_output()\n",
    "        uploaded_file = next(iter(change['new']))\n",
    "        content = io.BytesIO(uploaded_file['content'])\n",
    "        train_df = pd.read_csv(content)\n",
    "        print(f\"Train Dataset Uploaded\")\n",
    "        display(train_df.head())\n",
    "\n",
    "def handle_test_upload(change):\n",
    "    global test_df\n",
    "    with output:\n",
    "        clear_output()\n",
    "        uploaded_file = next(iter(change['new']))\n",
    "        content = io.BytesIO(uploaded_file['content'])\n",
    "        test_df = pd.read_csv(content)\n",
    "        print(f\"Test Dataset Uploaded\")\n",
    "        display(test_df.head())\n",
    "\n",
    "# File upload widgets\n",
    "train_upload = widgets.FileUpload(accept='.csv', multiple=False)\n",
    "test_upload = widgets.FileUpload(accept='.csv', multiple=False)\n",
    "train_upload.observe(handle_train_upload, names='value')\n",
    "test_upload.observe(handle_test_upload, names='value')\n",
    "\n",
    "# Function to print final selection\n",
    "\n",
    "from data_integrity import *\n",
    "def display_selection(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_checks = [\n",
    "            check for check, widget in {**train_test_widgets, **data_integrity_widgets}.items() if widget.value\n",
    "        ]\n",
    "        \n",
    "        final_dict = {}\n",
    "        for check in selected_checks:\n",
    "            if check in checks_with_params and check in param_box.check_param_inputs:\n",
    "                params = {param_widget.description: param_widget.value for param_widget in param_box.check_param_inputs[check]}\n",
    "                final_dict[check] = params\n",
    "            #else:\n",
    "            #    final_dict[check] = {\"parameters\": None}\n",
    "        \n",
    "        print(\"Selected Checks with Parameters:\")\n",
    "        print(final_dict)\n",
    "\n",
    "        # Call the validation function from your external module\n",
    "        print(list(final_dict.keys()))\n",
    "        print(checks_with_params)\n",
    "        validation_results = run_deepchecks(train_df, test_df, label, list(final_dict.keys()), checks_with_params)\n",
    "    \n",
    "submit_button = widgets.Button(description='Submit', button_style='primary', layout=widgets.Layout(width='200px'))\n",
    "submit_button.on_click(display_selection)\n",
    "\n",
    "# Layout adjustments\n",
    "check_columns = widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Data Integrity Checks\"), widgets.VBox(list(data_integrity_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "    widgets.VBox([widgets.Label(\"Train-Test Checks\"), widgets.VBox(list(train_test_widgets.values()))], layout=widgets.Layout(width='50%', padding='10px')),\n",
    "])\n",
    "\n",
    "# Hide check options initially\n",
    "update_check_visibility()\n",
    "\n",
    "# Display widgets\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Upload Training Dataset (CSV)\"),\n",
    "    train_upload,\n",
    "    widgets.Label(\"Upload Test Dataset (CSV)\"),\n",
    "    test_upload,\n",
    "    widgets.Label(\"Select Suites\", layout=widgets.Layout(margin='10px 0', font_weight='bold')),\n",
    "    widgets.HBox([suite_data_integrity, suite_train_test]),\n",
    "    check_columns,\n",
    "    param_box,\n",
    "    submit_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddd286f9-6cdf-43bc-9700-82195142a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam  = {'Data Duplicates': {'parameters': {'max_duplicate_fraction': 0.1}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0206eb4a-5d26-4ee8-9c29-991d012ad60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Data Duplicates'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa4cec-f8ba-4bcd-b1ec-6b1e6c064de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a69863-199e-48ec-b6e2-bf275ed90255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe0e52-c3e5-406b-9a5a-7561ebe073b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1a253-a4b8-4ee2-929b-bb01128d2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b9e87-f40d-4b3a-a324-d442aed1397b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20424518-1277-4115-9ad9-90f7a03ac1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006a459-055f-488d-bb40-084894440dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Train Test Validation Suite Starts Here ####\n",
    "\n",
    "from collections import OrderedDict\n",
    "import deepchecks\n",
    "import deepchecks.tabular.checks as checks\n",
    "import ipywidgets as widgets\n",
    "from deepchecks.tabular import Suite, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Get user-defined parameter values for checks that require input.\"\"\"\n",
    "    params = {\n",
    "        'label_drift_threshold': 0.1,\n",
    "        'prediction_drift_threshold': 0.1,\n",
    "        'correlation_threshold': 0.9,\n",
    "        'max_missing_ratio': 0.05\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_train_test_checks(params):\n",
    "    \"\"\"Retrieve and organize train-test validation checks into an OrderedDict with conditions.\"\"\"\n",
    "    check_dict = OrderedDict({\n",
    "        1: checks.CategoryMismatchTrainTest().add_condition_new_category_ratio_less_or_equal(0),\n",
    "        2: checks.DateTrainTestLeakageDuplicates().add_condition_leakage_ratio_less_or_equal(max_ratio = 0),\n",
    "        3: checks.LabelDrift().add_condition_drift_score_less_than(params['label_drift_threshold']),\n",
    "        4: checks.FeatureDrift().add_condition_drift_score_less_than(max_allowed_categorical_score = 0.2, max_allowed_numeric_score = 0.2),\n",
    "        5: checks.MultivariateDrift().add_condition_overall_drift_value_less_than(max_drift_value = 0.25),\n",
    "        6: checks.TrainTestSamplesMix()\n",
    "    })\n",
    "    from deepchecks.core.checks import BaseCheck\n",
    "    \n",
    "    return OrderedDict((k, v) for k, v in check_dict.items() if isinstance(v, BaseCheck))\n",
    "\n",
    "def create_train_test_suite():\n",
    "    \"\"\"Create a Train-Test Evaluation suite with configured conditions.\"\"\"\n",
    "    params = get_user_input()\n",
    "    check_dict = get_train_test_checks(params)\n",
    "    suite = Suite(\"Train-Test Evaluation Suite\", *check_dict.values())\n",
    "    return suite\n",
    "\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample train and test datasets.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1.2, 1000),\n",
    "        'feature2': np.random.normal(5.5, 2.2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    train_dataset = Dataset(train_data, label='label')\n",
    "    test_dataset = Dataset(test_data, label='label')\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Example Usage:\n",
    "# suite = create_train_test_suite()\n",
    "# train_dataset, test_dataset = generate_sample_data()\n",
    "# suite.run(train_dataset, test_dataset)\n",
    "# Example Usage:\n",
    "suite = create_train_test_suite()\n",
    "train_dataset, test_dataset = generate_sample_data()\n",
    "suite.run(train_dataset, test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Model Evaluation Suite Starts Here ####\n",
    "\n",
    "from collections import OrderedDict\n",
    "import deepchecks.tabular.checks as checks\n",
    "from deepchecks.tabular import Suite, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# User-defined input parameters\n",
    "TRAIN_DATA_PATH = 'train.csv'  # Path to train dataset\n",
    "TEST_DATA_PATH = 'test.csv'  # Path to test dataset\n",
    "\n",
    "# Allow user to select tests to run\n",
    "AVAILABLE_CHECKS = {\n",
    "    'TrainTestPerformance': checks.TrainTestPerformance(),\n",
    "    'RocReport': checks.RocReport(),\n",
    "    'SimpleModelComparison': checks.SimpleModelComparison(),\n",
    "    'CalibrationScore': checks.CalibrationScore()\n",
    "}\n",
    "\n",
    "# User-defined test thresholds\n",
    "TEST_THRESHOLDS = {\n",
    "    'TrainTestPerformance': {'min_score': 0.20},\n",
    "    'RocReport': {'min_auc': 0.7}\n",
    "}\n",
    "\n",
    "print(\"Available checks:\")\n",
    "for i, check_name in enumerate(AVAILABLE_CHECKS.keys()):\n",
    "    print(f\"{i + 1}. {check_name}\")\n",
    "\n",
    "selected_indices = input(\"Enter check numbers to run (comma-separated, e.g., 1,3): \")\n",
    "selected_indices = [int(idx.strip()) - 1 for idx in selected_indices.split(',') if idx.strip().isdigit()]\n",
    "\n",
    "SELECTED_CHECKS = []\n",
    "for i in selected_indices:\n",
    "    if i in range(len(AVAILABLE_CHECKS)):\n",
    "        check_name = list(AVAILABLE_CHECKS.keys())[i]\n",
    "        check = AVAILABLE_CHECKS[check_name]\n",
    "        if check_name in TEST_THRESHOLDS:\n",
    "            check = check.add_condition_test_performance_greater_than(**TEST_THRESHOLDS[check_name])\n",
    "        SELECTED_CHECKS.append(check)\n",
    "\n",
    "def create_model_evaluation_suite():\n",
    "    \"\"\"Create a Model Evaluation suite with user-selected checks.\"\"\"\n",
    "    return Suite(\"Model Evaluation Suite\", *SELECTED_CHECKS)\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Load CSV file into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Uploaded file is empty.\")\n",
    "        print(f\"Loaded {file_path} with shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_sample_model(train_df):\n",
    "    \"\"\"Train a sample RandomForest model.\"\"\"\n",
    "    X_train = train_df.drop(columns=['label'])\n",
    "    y_train = train_df['label']\n",
    "    model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(train_df, test_df):\n",
    "    \"\"\"Run model evaluation checks using Deepchecks.\"\"\"\n",
    "    try:\n",
    "        print(\"Creating datasets...\")\n",
    "        train_dataset = Dataset(train_df, label='label')\n",
    "        test_dataset = Dataset(test_df, label='label')\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        model = train_sample_model(train_df)\n",
    "        \n",
    "        print(\"Creating Deepchecks suite...\")\n",
    "        suite = create_model_evaluation_suite()\n",
    "        \n",
    "        print(\"Running suite...\")\n",
    "        result = suite.run(train_dataset, test_dataset, model)\n",
    "        \n",
    "        print(\"Evaluation completed. Showing results:\")\n",
    "        result.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = load_csv(TRAIN_DATA_PATH)\n",
    "test_df = load_csv(TEST_DATA_PATH)\n",
    "   \n",
    "if train_df is not None and test_df is not None:\n",
    "        evaluate_model(train_df, test_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec1e63-1f0a-4131-907d-77119be9de6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e753f-d0bc-4bc8-8b36-46ca6043fe52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16d199-694f-43b9-8cb0-ac8612be6aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4658741-e996-4c29-9bf0-e18746ff9e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3555f31-4db1-4130-8afc-691086855886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df513dae-3338-4b48-acd1-86c08addf498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b5237-6e87-411a-a993-4e7e881223cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f374a02-95bc-4494-b246-eec738f42ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44353b0b-b9dd-4220-905b-550ddbe9076f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f8a76-6236-4b6a-ab8b-99420e1120b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c962a37-c4b8-4867-8c36-433c1a81a8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371dfad1-981b-443e-a889-e22c1b46c462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd51e6-8abe-4276-9805-9ab27084fc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a20fae-a910-446f-b100-829a32461701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157ddad-90ea-4aa8-96e8-821984cbaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.core import CheckResult\n",
    "from deepchecks.core.checks import BaseCheck\n",
    "from deepchecks.tabular.feature_importance import calculate_feature_importance\n",
    "import pandas as pd\n",
    "\n",
    "class FeatureImportanceCheck(BaseCheck):\n",
    "    \"\"\"Custom Deepchecks check to compare feature importance between train and test datasets.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Feature Importance Comparison\")\n",
    "\n",
    "    def run(self, train_dataset, test_dataset, model):\n",
    "        # Validate input\n",
    "        if model is None:\n",
    "            return CheckResult(value=\"No model provided\", display=\"error\")\n",
    "\n",
    "        # Compute feature importance for train and test sets\n",
    "        feature_importance_train = calculate_feature_importance(model, train_dataset)\n",
    "        feature_importance_test = calculate_feature_importance(model, test_dataset)\n",
    "\n",
    "        # Compute absolute differences\n",
    "        importance_diff = abs(feature_importance_train.importance - feature_importance_test.importance)\n",
    "\n",
    "        # Create a DataFrame with results\n",
    "        result_df = pd.DataFrame({\n",
    "            'Feature': feature_importance_train.feature_names,\n",
    "            'Train Importance': feature_importance_train.importance,\n",
    "            'Test Importance': feature_importance_test.importance,\n",
    "            'Difference': importance_diff\n",
    "        }).sort_values(by='Difference', ascending=False)\n",
    "\n",
    "        return CheckResult(value=result_df, display=result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb26086-6cd8-4d69-9a6b-31d0a88fe84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Suite\n",
    "\n",
    "def create_model_evaluation_suite():\n",
    "    \"\"\"Create a Model Evaluation suite with configured conditions.\"\"\"\n",
    "    suite = Suite(\n",
    "        \"Model Evaluation Suite\",\n",
    "        FeatureImportanceCheck()  # Adding the custom check\n",
    "    )\n",
    "    return suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea5a48-526a-4040-a826-325683a2d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataset, test_dataset):\n",
    "    \"\"\"Run model evaluation checks using deepchecks.\"\"\"\n",
    "    suite = create_model_evaluation_suite()\n",
    "    result = suite.run(train_dataset, test_dataset, model)\n",
    "    result.show()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ce98d-65b2-4ff0-b19d-ec4a61e24c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd5a8a-79c5-437f-b2df-14ce3e97e971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ecd0a-a05b-4ba6-a150-f82614d0e20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
