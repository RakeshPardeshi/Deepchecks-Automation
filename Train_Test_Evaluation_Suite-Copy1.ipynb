{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b9ab35-e488-41ad-9e1e-0c73e1dcee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - You are using deepchecks version 0.19.0, however a newer version is available. Deepchecks is frequently updated with major improvements. You should consider upgrading via the \"python -m pip install --upgrade deepchecks\" command.\n"
     ]
    }
   ],
   "source": [
    "from train_test_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10f62ac-3d2a-48b9-ad3c-bbb9fdb36fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train.csv\"\n",
    "test_path = \"test.csv\"\n",
    "label = \"label\"\n",
    "#model_file = \"model.pkl\"\n",
    "#prediction_label_column = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42101aa3-bf83-44a8-9f5b-0c1e54784fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Train Test Validation Checks:\n",
      "1. String Mismatch Comparison\n",
      "2. Train Test Samples Mix\n",
      "3. New Label Train Test\n",
      "4. New Category Train Test\n",
      "5. Label Drift\n",
      "6. Feature Drift\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter check numbers to run (comma-separated, e.g., 1,3,5):  1,2,3,4,5,6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['String Mismatch Comparison', 'Train Test Samples Mix', 'New Label Train Test', 'New Category Train Test', 'Label Drift', 'Feature Drift']\n"
     ]
    }
   ],
   "source": [
    "# Display available checks\n",
    "print(\"\\nAvailable Train Test Validation Checks:\")\n",
    "for i, test in enumerate(check_options.keys()):\n",
    "    print(f\"{i + 1}. {test}\")\n",
    "\n",
    "### User selects which checks to run\n",
    "selected_indices = input(\"Enter check numbers to run (comma-separated, e.g., 1,3,5): \")\n",
    "selected_indices = [int(idx.strip()) - 1 for idx in selected_indices.split(',') if idx.strip().isdigit()]\n",
    "\n",
    "### Map indices to selected check names\n",
    "selected_tests = [list(check_options.keys())[i] for i in selected_indices]\n",
    "print(selected_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2186520-d708-463e-81fd-5008b96b80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\"max_allowed_categorical_score\": 0.2, \"max_allowed_numeric_score\": 0.2, \"allowed_num_features_exceeding_threshold\": 0},    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58de29c9-5136-41ea-90f6-e03f104fb5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded train.csv with shape: (1000, 6)\n",
      "Loaded test.csv with shape: (1000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 2 categorical features were inferred.: feature3, predicted_label\n",
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 2 categorical features were inferred.: feature3, predicted_label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepchecks\\tabular\\checks\\train_test_validation\\train_test_samples_mix.py:85: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16b860d662d4ec794fb1e8c1da75095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_UWIOYIQUYNY3ILKI635KZ51T2\">Custom Train Test …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load or create a sample dataset\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = load_csv(train_path)\n",
    "test_df = load_csv(test_path)  \n",
    "\n",
    "run_train_test(train_df, test_df, label, selected_tests, checks_with_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d73df3-3a65-4567-bd08-da73be035390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659e352-264e-4338-bd26-ff8d99b253a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec38d4d4-c5fd-49c9-a475-4ffd1976afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import deepchecks.tabular.checks as checks\n",
    "from deepchecks.tabular import Suite, Dataset\n",
    "\n",
    "from deepchecks.tabular.checks import (StringMismatchComparison, TrainTestSamplesMix, NewLabelTrainTest, NewCategoryTrainTest, LabelDrift, FeatureDrift)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7afe3208-a8c6-4532-8043-7168431eb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train.csv\"\n",
    "test_path = \"test.csv\"\n",
    "label = \"label\"\n",
    "#model_file = \"model.pkl\"\n",
    "#prediction_label_column = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38fe711e-e593-4335-a9bb-1e2278ae87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_ratio': 0.05}\n",
      "{'max_new': 0}\n",
      "{'max_new': 0}\n",
      "{'max_allowed_drift_score': 0.15}\n",
      "{'max_allowed_categorical_score': 0.2, 'max_allowed_numeric_score': 0.2, 'allowed_num_features_exceeding_threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import deepchecks.tabular.checks as checks\n",
    "from deepchecks.tabular import Suite, Dataset\n",
    "from deepchecks.tabular.checks import (StringMismatchComparison, TrainTestSamplesMix, NewLabelTrainTest, NewCategoryTrainTest, LabelDrift, FeatureDrift)\n",
    "                                \n",
    "\n",
    "\n",
    "# Define available checks (without parameters)\n",
    "check_options = {\n",
    "    \"String Mismatch Comparison\": StringMismatchComparison(),\n",
    "    \"Train Test Samples Mix\": TrainTestSamplesMix(),\n",
    "    \"New Label Train Test\": NewLabelTrainTest(),\n",
    "    \"New Category Train Test\": NewCategoryTrainTest(),\n",
    "    \"Label Drift\": LabelDrift(), \n",
    "    \"Feature Drift\": FeatureDrift(),\n",
    "}\n",
    "\n",
    "# Checks that require user input parameters\n",
    "checks_with_params = { \n",
    "    \"Train Test Samples Mix\": {\"max_ratio\": 0.05},\n",
    "    \"New Label Train Test\": {\"max_new\": 0},\n",
    "    \"New Category Train Test\": {\"max_new\": 0},\n",
    "    \"Label Drift\": {\"max_allowed_drift_score\": 0.15},\n",
    "    \"Feature Drift\": {\"max_allowed_categorical_score\": 0.2, \"max_allowed_numeric_score\": 0.2, \"allowed_num_features_exceeding_threshold\": 0},    \n",
    "}\n",
    "\n",
    "print(checks_with_params[\"Train Test Samples Mix\"])\n",
    "print(checks_with_params[\"New Label Train Test\"])\n",
    "print(checks_with_params[\"New Category Train Test\"])\n",
    "print(checks_with_params[\"Label Drift\"])\n",
    "print(checks_with_params[\"Feature Drift\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d559f4-56c0-4e5f-a0ca-eccbf8d5a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Train Test Validation Checks:\n",
      "1. String Mismatch Comparison\n",
      "2. Train Test Samples Mix\n",
      "3. New Label Train Test\n",
      "4. New Category Train Test\n",
      "5. Label Drift\n",
      "6. Feature Drift\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter check numbers to run (comma-separated, e.g., 1,3,5):  1,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['String Mismatch Comparison', 'Train Test Samples Mix']\n"
     ]
    }
   ],
   "source": [
    "# Display available checks\n",
    "print(\"\\nAvailable Train Test Validation Checks:\")\n",
    "for i, test in enumerate(check_options.keys()):\n",
    "    print(f\"{i + 1}. {test}\")\n",
    "\n",
    "### User selects which checks to run\n",
    "selected_indices = input(\"Enter check numbers to run (comma-separated, e.g., 1,3,5): \")\n",
    "selected_indices = [int(idx.strip()) - 1 for idx in selected_indices.split(',') if idx.strip().isdigit()]\n",
    "\n",
    "### Map indices to selected check names\n",
    "selected_tests = [list(check_options.keys())[i] for i in selected_indices]\n",
    "print(selected_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae3bf58-3767-43cd-8978-5d721f96a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_test_suite(data1, data2, label=None):\n",
    "    \"\"\"Run selected deepchecks data integrity tests on the given dataset.\"\"\"\n",
    "    dataset1 = Dataset(data1, label=label)\n",
    "    dataset2 = Dataset(data2, label=label)\n",
    "        \n",
    "    # Create selected checks with conditions where applicable\n",
    "    selected_checks = []\n",
    "    \n",
    "    for test in selected_tests:\n",
    "        if test == \"String Mismatch Comparison\":\n",
    "            check = StringMismatchComparison().add_condition_no_new_variants()\n",
    "        elif test == \"Train Test Samples Mix\":\n",
    "            check = TrainTestSamplesMix().add_condition_duplicates_ratio_less_or_equal(**checks_with_params[test])\n",
    "        elif test == \"New Label Train Test\":\n",
    "            check = NewLabelTrainTest().add_condition_new_labels_number_less_or_equal(**checks_with_params[test])\n",
    "        elif test == \"New Category Train Test\":\n",
    "            check = NewCategoryTrainTest().add_condition_new_categories_less_or_equal(**checks_with_params[test])\n",
    "        elif test == \"Label Drift\":\n",
    "            check = LabelDrift().add_condition_drift_score_less_than(**checks_with_params[test])   \n",
    "        elif test == \"Feature Drift\":\n",
    "            check = FeatureDrift().add_condition_drift_score_less_than(**checks_with_params[test])\n",
    "        else:\n",
    "            check = check_options[test]\n",
    "\n",
    "        selected_checks.append(check)\n",
    "    \n",
    "    # Create and run suite\n",
    "    suite = Suite(\"Custom Train Test Evaluation Suite\", *selected_checks)\n",
    "    result = suite.run(dataset1, dataset2)\n",
    "    # Show results\n",
    "    result.show()\n",
    "    return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c6d9575-0d1f-4a59-b32a-1fb30e5a0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    \"\"\"Load CSV file into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Uploaded file is empty.\")\n",
    "        print(f\"Loaded {file_path} with shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15ef0b5-0775-4d28-8eb6-06103418fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 2 categorical features were inferred.: feature3, predicted_label\n",
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 2 categorical features were inferred.: feature3, predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded train.csv with shape: (1000, 6)\n",
      "Loaded test.csv with shape: (1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepchecks\\tabular\\checks\\train_test_validation\\train_test_samples_mix.py:85: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9270c65849174f0cbbbddd41dbaadfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_MB9DCTD0OXO2YM34GGLHQJ48D\">Custom Train Test …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    print(\"Loading data...\")\n",
    "    train_df = load_csv(train_path)\n",
    "    test_df = load_csv(test_path)    \n",
    "    # Load or create a sample dataset\n",
    "    \n",
    "    run_train_test_suite(train_df, test_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd77707-d990-4b5b-af31-c992b5af73f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65725ce2-f4fd-48f7-a99a-fea008188f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905517d7-33f0-4b8d-9f5a-26f6ed1ce361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3da95-a062-4513-830c-9fbc90f9456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_checks(params):\n",
    "    \"\"\"Retrieve and organize train-test validation checks into an OrderedDict with conditions.\"\"\"\n",
    "    check_dict = OrderedDict({\n",
    "        1: checks.CategoryMismatchTrainTest().add_condition_new_category_ratio_less_or_equal(0),\n",
    "        2: checks.DateTrainTestLeakageDuplicates().add_condition_leakage_ratio_less_or_equal(max_ratio = 0),\n",
    "        3: checks.LabelDrift().add_condition_drift_score_less_than(params['label_drift_threshold']),\n",
    "        4: checks.FeatureDrift().add_condition_drift_score_less_than(max_allowed_categorical_score = 0.2, max_allowed_numeric_score = 0.2),\n",
    "        5: checks.MultivariateDrift().add_condition_overall_drift_value_less_than(max_drift_value = 0.25),\n",
    "        6: checks.TrainTestSamplesMix()\n",
    "    })\n",
    "    from deepchecks.core.checks import BaseCheck\n",
    "    \n",
    "    return OrderedDict((k, v) for k, v in check_dict.items() if isinstance(v, BaseCheck))\n",
    "\n",
    "def create_train_test_suite():\n",
    "    \"\"\"Create a Train-Test Evaluation suite with configured conditions.\"\"\"\n",
    "    params = get_user_input()\n",
    "    check_dict = get_train_test_checks(params)\n",
    "    suite = Suite(\"Train-Test Evaluation Suite\", *check_dict.values())\n",
    "    return suite\n",
    "\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample train and test datasets.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1.2, 1000),\n",
    "        'feature2': np.random.normal(5.5, 2.2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    train_dataset = Dataset(train_data, label='label')\n",
    "    test_dataset = Dataset(test_data, label='label')\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Example Usage:\n",
    "# suite = create_train_test_suite()\n",
    "# train_dataset, test_dataset = generate_sample_data()\n",
    "# suite.run(train_dataset, test_dataset)\n",
    "# Example Usage:\n",
    "suite = create_train_test_suite()\n",
    "train_dataset, test_dataset = generate_sample_data()\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba0c09-6a1c-4ddc-a108-e2187c8282d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ed7bf-4df4-4eba-838e-c38a4f758804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393af4af-3260-4d8a-8b08-736932497eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7f474-c39d-4998-bdf4-aa79e32e2c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f2cf29b-02c0-48c7-9c4e-ee75ded00a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import deepchecks\n",
    "import deepchecks.tabular.checks as checks\n",
    "import ipywidgets as widgets\n",
    "from deepchecks.tabular import Suite, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Get user-defined parameter values for checks that require input.\"\"\"\n",
    "    params = {\n",
    "        'label_drift_threshold': 0.1,\n",
    "        'prediction_drift_threshold': 0.1,\n",
    "        'correlation_threshold': 0.9,\n",
    "        'max_missing_ratio': 0.05\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_train_test_checks(params):\n",
    "    \"\"\"Retrieve and organize train-test validation checks into an OrderedDict with conditions.\"\"\"\n",
    "    check_dict = OrderedDict({\n",
    "        1: checks.CategoryMismatchTrainTest().add_condition_new_category_ratio_less_or_equal(0),\n",
    "        2: checks.DateTrainTestLeakageDuplicates().add_condition_leakage_ratio_less_or_equal(max_ratio = 0),\n",
    "        3: checks.LabelDrift().add_condition_drift_score_less_than(params['label_drift_threshold']),\n",
    "        4: checks.FeatureDrift().add_condition_drift_score_less_than(max_allowed_categorical_score = 0.2, max_allowed_numeric_score = 0.2),\n",
    "        5: checks.MultivariateDrift().add_condition_overall_drift_value_less_than(max_drift_value = 0.25),\n",
    "        6: checks.TrainTestSamplesMix()\n",
    "    })\n",
    "    from deepchecks.core.checks import BaseCheck\n",
    "    \n",
    "    return OrderedDict((k, v) for k, v in check_dict.items() if isinstance(v, BaseCheck))\n",
    "\n",
    "def create_train_test_suite():\n",
    "    \"\"\"Create a Train-Test Evaluation suite with configured conditions.\"\"\"\n",
    "    params = get_user_input()\n",
    "    check_dict = get_train_test_checks(params)\n",
    "    suite = Suite(\"Train-Test Evaluation Suite\", *check_dict.values())\n",
    "    return suite\n",
    "\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample train and test datasets.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    train_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1.2, 1000),\n",
    "        'feature2': np.random.normal(5.5, 2.2, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    \n",
    "    train_dataset = Dataset(train_data, label='label')\n",
    "    test_dataset = Dataset(test_data, label='label')\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Example Usage:\n",
    "# suite = create_train_test_suite()\n",
    "# train_dataset, test_dataset = generate_sample_data()\n",
    "# suite.run(train_dataset, test_dataset)\n",
    "# Example Usage:\n",
    "suite = create_train_test_suite()\n",
    "train_dataset, test_dataset = generate_sample_data()\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35788ef5-9567-439f-8cd8-b4220acb422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15776\\3228969167.py:26: DeprecationWarning:\n",
      "\n",
      "The TrainTestPredictionDrift check is deprecated and will be removed in the 0.14 version. Please use the PredictionDrift check instead.\n",
      "\n",
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 1 categorical features were inferred.: feature3\n",
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 1 categorical features were inferred.: feature3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\deepchecks\\tabular\\checks\\train_test_validation\\train_test_samples_mix.py:85: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0451e95c74432fa50ab68e86ee6223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_AGNU1ZRBWVKQ44RP1L8Z221CB\">Train-Test Evaluat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example Usage:\n",
    "suite = create_train_test_suite()\n",
    "train_dataset, test_dataset = generate_sample_data()\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09ce74c-f962-40cc-b09b-0440d20b09c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f78369-796e-4ad0-90b7-cc777192ade6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b638e-adfc-4488-ba57-f2193b3f2e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa692c4d-d385-42d7-a2b6-9f8e9d09bf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec67ff-6b88-4156-bee6-492b060f8399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3f3a5-61b7-491e-a108-c6d01c1e34a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
